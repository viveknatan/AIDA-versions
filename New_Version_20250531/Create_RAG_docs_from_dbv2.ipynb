{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import psycopg2\n",
    "from typing import List\n",
    "from datetime import datetime\n",
    "\n",
    "def create_comprehensive_northwind_business_documents(\n",
    "    host: str,\n",
    "    username: str,\n",
    "    password: str,\n",
    "    database: str = \"neondb\",\n",
    "    port: int = 5432,\n",
    "    schema: str = \"northwind\"\n",
    ") -> List[str]:\n",
    "    \"\"\"\n",
    "    Execute comprehensive SQL queries against PostgreSQL Northwind database hosted on Neon \n",
    "    and create detailed business-friendly documents for vector search and RAG applications.\n",
    "    \n",
    "    This expanded version includes deep analysis of all business aspects including:\n",
    "    - Customer demographics and behavior patterns\n",
    "    - Product performance and inventory management\n",
    "    - Employee productivity and territory analysis\n",
    "    - Supplier relationships and logistics\n",
    "    - Financial performance and trends\n",
    "    - Geographic distribution and shipping patterns\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create connection string for Neon\n",
    "    conn_string = f\"postgresql://{username}:{password}@{host}:{port}/{database}?sslmode=require\"\n",
    "    \n",
    "    documents = []\n",
    "    \n",
    "    try:\n",
    "        print(\"Connecting to Northwind database and generating comprehensive business documents...\")\n",
    "        \n",
    "        # 1. COMPREHENSIVE CUSTOMER ANALYSIS\n",
    "        print(\"Generating customer analysis document...\")\n",
    "        \n",
    "        # Customer demographics and distribution\n",
    "        customer_demographics_query = f\"\"\"\n",
    "        SELECT \n",
    "            country,\n",
    "            city,\n",
    "            COUNT(*) as customer_count,\n",
    "            STRING_AGG(DISTINCT contact_title, ', ') as job_titles,\n",
    "            STRING_AGG(company_name, '; ' ORDER BY company_name) as sample_companies\n",
    "        FROM {schema}.customers \n",
    "        GROUP BY country, city\n",
    "        ORDER BY customer_count DESC, country, city\n",
    "        \"\"\"\n",
    "        \n",
    "        df_demographics = pd.read_sql_query(customer_demographics_query, conn_string)\n",
    "        \n",
    "        customer_doc = \"NORTHWIND COMPREHENSIVE CUSTOMER ANALYSIS:\\n\\n\"\n",
    "        customer_doc += f\"CUSTOMER BASE OVERVIEW:\\n\"\n",
    "        customer_doc += f\"Northwind serves {df_demographics['customer_count'].sum()} customers across {len(df_demographics['country'].unique())} countries and {len(df_demographics)} cities.\\n\\n\"\n",
    "        \n",
    "        # Country analysis\n",
    "        country_summary = df_demographics.groupby('country').agg({\n",
    "            'customer_count': 'sum',\n",
    "            'city': 'count'\n",
    "        }).sort_values('customer_count', ascending=False)\n",
    "        \n",
    "        customer_doc += \"CUSTOMER DISTRIBUTION BY COUNTRY:\\n\"\n",
    "        for country, row in country_summary.head(15).iterrows():\n",
    "            customer_doc += f\"- {country}: {row['customer_count']} customers across {row['city']} cities\\n\"\n",
    "        \n",
    "        # Detailed customer profiles with contact information\n",
    "        detailed_customers_query = f\"\"\"\n",
    "        SELECT \n",
    "            customer_id,\n",
    "            company_name,\n",
    "            contact_name,\n",
    "            contact_title,\n",
    "            city,\n",
    "            region,\n",
    "            country,\n",
    "            phone,\n",
    "            fax\n",
    "        FROM {schema}.customers\n",
    "        ORDER BY country, city, company_name\n",
    "        \"\"\"\n",
    "        \n",
    "        df_detailed = pd.read_sql_query(detailed_customers_query, conn_string)\n",
    "        \n",
    "        customer_doc += \"\\n\\nDETAILED CUSTOMER DIRECTORY:\\n\"\n",
    "        \n",
    "        # Group by country for better organization\n",
    "        for country in df_detailed['country'].unique()[:10]:  # Top 10 countries\n",
    "            country_customers = df_detailed[df_detailed['country'] == country]\n",
    "            customer_doc += f\"\\n{country.upper()} ({len(country_customers)} customers):\\n\"\n",
    "            \n",
    "            for _, customer in country_customers.head(8).iterrows():  # Top 8 per country\n",
    "                region_info = f\", {customer['region']}\" if pd.notna(customer['region']) else \"\"\n",
    "                fax_info = f\", Fax: {customer['fax']}\" if pd.notna(customer['fax']) else \"\"\n",
    "                customer_doc += f\"  • {customer['company_name']} - {customer['contact_name']} ({customer['contact_title']})\\n\"\n",
    "                customer_doc += f\"    Location: {customer['city']}{region_info}, Phone: {customer['phone']}{fax_info}\\n\"\n",
    "        \n",
    "        documents.append(customer_doc)\n",
    "        \n",
    "        # 2. CUSTOMER PURCHASING BEHAVIOR AND TOP PERFORMERS\n",
    "        print(\"Generating customer purchasing behavior analysis...\")\n",
    "        \n",
    "        customer_behavior_query = f\"\"\"\n",
    "        WITH customer_metrics AS (\n",
    "            SELECT \n",
    "                c.customer_id,\n",
    "                c.company_name,\n",
    "                c.contact_name,\n",
    "                c.city,\n",
    "                c.region,\n",
    "                c.country,\n",
    "                COUNT(DISTINCT o.order_id) as total_orders,\n",
    "                COUNT(DISTINCT DATE_PART('year', o.order_date)) as years_active,\n",
    "                MIN(o.order_date) as first_order_date,\n",
    "                MAX(o.order_date) as last_order_date,\n",
    "                ROUND(SUM(od.unit_price * od.quantity * (1 - od.discount))::numeric, 2) as total_revenue,\n",
    "                ROUND(AVG(od.unit_price * od.quantity * (1 - od.discount))::numeric, 2) as avg_order_value,\n",
    "                SUM(od.quantity) as total_items_purchased,\n",
    "                ROUND(AVG(o.freight)::numeric, 2) as avg_shipping_cost,\n",
    "                COUNT(DISTINCT od.product_id) as unique_products_bought\n",
    "            FROM {schema}.customers c\n",
    "            JOIN {schema}.orders o ON c.customer_id = o.customer_id\n",
    "            JOIN {schema}.order_details od ON o.order_id = od.order_id\n",
    "            GROUP BY c.customer_id, c.company_name, c.contact_name, c.city, c.region, c.country\n",
    "        )\n",
    "        SELECT * FROM customer_metrics\n",
    "        ORDER BY total_revenue DESC\n",
    "        \"\"\"\n",
    "        \n",
    "        df_behavior = pd.read_sql_query(customer_behavior_query, conn_string)\n",
    "        \n",
    "        behavior_doc = \"NORTHWIND CUSTOMER PURCHASING BEHAVIOR ANALYSIS:\\n\\n\"\n",
    "        \n",
    "        # Top customers by revenue\n",
    "        behavior_doc += \"TOP 20 CUSTOMERS BY TOTAL REVENUE:\\n\"\n",
    "        for i, row in df_behavior.head(20).iterrows():\n",
    "            region = f\", {row['region']}\" if pd.notna(row['region']) else \"\"\n",
    "            years_span = f\"{row['first_order_date']:.10}\" + \" to \" + f\"{row['last_order_date']:.10}\"\n",
    "            \n",
    "            behavior_doc += f\"{i+1}. {row['company_name']} ({row['country']})\\n\"\n",
    "            behavior_doc += f\"   • Total Revenue: ${row['total_revenue']:,.2f} across {row['total_orders']} orders\\n\"\n",
    "            behavior_doc += f\"   • Average Order Value: ${row['avg_order_value']:,.2f}\\n\"\n",
    "            behavior_doc += f\"   • Active Period: {years_span} ({row['years_active']} years)\\n\"\n",
    "            behavior_doc += f\"   • Location: {row['city']}{region}\\n\"\n",
    "            behavior_doc += f\"   • Products Diversity: {row['unique_products_bought']} different products, {row['total_items_purchased']} total items\\n\\n\"\n",
    "        \n",
    "        # Customer segmentation analysis\n",
    "        behavior_doc += \"CUSTOMER SEGMENTATION ANALYSIS:\\n\"\n",
    "        revenue_percentiles = df_behavior['total_revenue'].quantile([0.25, 0.5, 0.75, 0.9, 0.95])\n",
    "        \n",
    "        behavior_doc += f\"• Premium Customers (Top 5%): ${revenue_percentiles[0.95]:,.2f}+ revenue ({len(df_behavior[df_behavior['total_revenue'] >= revenue_percentiles[0.95]])} customers)\\n\"\n",
    "        behavior_doc += f\"• High-Value Customers (Top 10%): ${revenue_percentiles[0.9]:,.2f}+ revenue ({len(df_behavior[df_behavior['total_revenue'] >= revenue_percentiles[0.9]])} customers)\\n\"\n",
    "        behavior_doc += f\"• Regular Customers (Median): ${revenue_percentiles[0.5]:,.2f} revenue\\n\"\n",
    "        behavior_doc += f\"• Average Order Value Range: ${df_behavior['avg_order_value'].min():,.2f} - ${df_behavior['avg_order_value'].max():,.2f}\\n\"\n",
    "        \n",
    "        # Geographic revenue distribution\n",
    "        geographic_revenue = df_behavior.groupby('country').agg({\n",
    "            'total_revenue': 'sum',\n",
    "            'total_orders': 'sum',\n",
    "            'company_name': 'count'\n",
    "        }).sort_values('total_revenue', ascending=False)\n",
    "        \n",
    "        behavior_doc += \"\\nREVENUE BY COUNTRY:\\n\"\n",
    "        for country, row in geographic_revenue.head(10).iterrows():\n",
    "            avg_revenue_per_customer = row['total_revenue'] / row['company_name']\n",
    "            behavior_doc += f\"• {country}: ${row['total_revenue']:,.2f} total (${avg_revenue_per_customer:,.2f} avg per customer)\\n\"\n",
    "        \n",
    "        documents.append(behavior_doc)\n",
    "        \n",
    "        # 3. COMPREHENSIVE PRODUCT CATALOG AND PERFORMANCE\n",
    "        print(\"Generating comprehensive product analysis...\")\n",
    "        \n",
    "        product_analysis_query = f\"\"\"\n",
    "        WITH product_performance AS (\n",
    "            SELECT \n",
    "                p.product_id,\n",
    "                p.product_name,\n",
    "                c.category_name,\n",
    "                s.company_name as supplier_name,\n",
    "                s.country as supplier_country,\n",
    "                p.quantity_per_unit,\n",
    "                p.unit_price,\n",
    "                p.units_in_stock,\n",
    "                p.units_on_order,\n",
    "                p.reorder_level,\n",
    "                p.discontinued,\n",
    "                COALESCE(SUM(od.quantity), 0) as total_quantity_sold,\n",
    "                COALESCE(ROUND(SUM(od.unit_price * od.quantity * (1 - od.discount))::numeric, 2), 0) as total_revenue,\n",
    "                COALESCE(COUNT(DISTINCT od.order_id), 0) as orders_count,\n",
    "                COALESCE(ROUND(AVG(od.unit_price * od.quantity * (1 - od.discount))::numeric, 2), 0) as avg_order_line_value\n",
    "            FROM {schema}.products p\n",
    "            JOIN {schema}.categories c ON p.category_id = c.category_id\n",
    "            JOIN {schema}.suppliers s ON p.supplier_id = s.supplier_id\n",
    "            LEFT JOIN {schema}.order_details od ON p.product_id = od.product_id\n",
    "            GROUP BY p.product_id, p.product_name, c.category_name, s.company_name, s.country,\n",
    "                     p.quantity_per_unit, p.unit_price, p.units_in_stock, p.units_on_order, \n",
    "                     p.reorder_level, p.discontinued\n",
    "        )\n",
    "        SELECT * FROM product_performance\n",
    "        ORDER BY total_revenue DESC\n",
    "        \"\"\"\n",
    "        \n",
    "        df_products = pd.read_sql_query(product_analysis_query, conn_string)\n",
    "        \n",
    "        product_doc = \"NORTHWIND COMPREHENSIVE PRODUCT CATALOG AND PERFORMANCE:\\n\\n\"\n",
    "        \n",
    "        # Category overview\n",
    "        category_performance = df_products.groupby('category_name').agg({\n",
    "            'product_id': 'count',\n",
    "            'total_revenue': 'sum',\n",
    "            'total_quantity_sold': 'sum',\n",
    "            'unit_price': 'mean',\n",
    "            'units_in_stock': 'sum'\n",
    "        }).sort_values('total_revenue', ascending=False)\n",
    "        \n",
    "        product_doc += f\"PRODUCT PORTFOLIO OVERVIEW:\\n\"\n",
    "        product_doc += f\"Total Products: {len(df_products)} across {len(category_performance)} categories\\n\"\n",
    "        product_doc += f\"Active Products: {len(df_products[df_products['discontinued'] == 0])}\\n\"\n",
    "        product_doc += f\"Discontinued Products: {len(df_products[df_products['discontinued'] == 1])}\\n\\n\"\n",
    "        \n",
    "        product_doc += \"CATEGORY PERFORMANCE ANALYSIS:\\n\"\n",
    "        for category, row in category_performance.iterrows():\n",
    "            product_doc += f\"• {category}: {row['product_id']} products, ${row['total_revenue']:,.2f} revenue\\n\"\n",
    "            product_doc += f\"  - {row['total_quantity_sold']:,.0f} units sold, avg price: ${row['unit_price']:,.2f}\\n\"\n",
    "            product_doc += f\"  - Current inventory: {row['units_in_stock']:,.0f} units\\n\"\n",
    "        \n",
    "        # Top performing products\n",
    "        product_doc += \"\\nTOP 25 PRODUCTS BY REVENUE:\\n\"\n",
    "        for i, row in df_products.head(25).iterrows():\n",
    "            discontinued_status = \" [DISCONTINUED]\" if row['discontinued'] == 1 else \"\"\n",
    "            stock_status = \"⚠️ LOW STOCK\" if row['units_in_stock'] <= row['reorder_level'] else \"✅ IN STOCK\"\n",
    "            \n",
    "            product_doc += f\"{i+1}. {row['product_name']} ({row['category_name']}){discontinued_status}\\n\"\n",
    "            product_doc += f\"   • Revenue: ${row['total_revenue']:,.2f} from {row['total_quantity_sold']} units sold\\n\"\n",
    "            product_doc += f\"   • Price: ${row['unit_price']:.2f} per {row['quantity_per_unit']}\\n\"\n",
    "            product_doc += f\"   • Supplier: {row['supplier_name']} ({row['supplier_country']})\\n\"\n",
    "            product_doc += f\"   • Inventory: {row['units_in_stock']} in stock, {row['units_on_order']} on order ({stock_status})\\n\\n\"\n",
    "        \n",
    "        # Inventory management insights\n",
    "        low_stock_products = df_products[df_products['units_in_stock'] <= df_products['reorder_level']]\n",
    "        high_revenue_low_stock = low_stock_products[low_stock_products['total_revenue'] > df_products['total_revenue'].median()]\n",
    "        \n",
    "        product_doc += f\"INVENTORY MANAGEMENT ALERTS:\\n\"\n",
    "        product_doc += f\"• Products below reorder level: {len(low_stock_products)}\\n\"\n",
    "        product_doc += f\"• High-revenue products with low stock: {len(high_revenue_low_stock)}\\n\"\n",
    "        \n",
    "        if len(high_revenue_low_stock) > 0:\n",
    "            product_doc += \"  Critical reorder needed for:\\n\"\n",
    "            for _, product in high_revenue_low_stock.head(5).iterrows():\n",
    "                product_doc += f\"    - {product['product_name']}: {product['units_in_stock']} units (${product['total_revenue']:,.0f} revenue)\\n\"\n",
    "        \n",
    "        documents.append(product_doc)\n",
    "        \n",
    "        # 4. SUPPLIER RELATIONSHIPS AND LOGISTICS\n",
    "        print(\"Generating supplier analysis...\")\n",
    "        \n",
    "        supplier_analysis_query = f\"\"\"\n",
    "        WITH supplier_metrics AS (\n",
    "            SELECT \n",
    "                s.supplier_id,\n",
    "                s.company_name,\n",
    "                s.contact_name,\n",
    "                s.contact_title,\n",
    "                s.city,\n",
    "                s.region,\n",
    "                s.country,\n",
    "                s.phone,\n",
    "                s.fax,\n",
    "                COUNT(p.product_id) as products_supplied,\n",
    "                COUNT(CASE WHEN p.discontinued = 0 THEN 1 END) as active_products,\n",
    "                ROUND(AVG(p.unit_price)::numeric, 2) as avg_product_price,\n",
    "                SUM(p.units_in_stock) as total_inventory_units,\n",
    "                COALESCE(SUM(od.quantity), 0) as total_units_sold,\n",
    "                COALESCE(ROUND(SUM(od.unit_price * od.quantity * (1 - od.discount))::numeric, 2), 0) as total_revenue_generated\n",
    "            FROM {schema}.suppliers s\n",
    "            JOIN {schema}.products p ON s.supplier_id = p.supplier_id\n",
    "            LEFT JOIN {schema}.order_details od ON p.product_id = od.product_id\n",
    "            GROUP BY s.supplier_id, s.company_name, s.contact_name, s.contact_title,\n",
    "                     s.city, s.region, s.country, s.phone, s.fax\n",
    "        )\n",
    "        SELECT * FROM supplier_metrics\n",
    "        ORDER BY total_revenue_generated DESC\n",
    "        \"\"\"\n",
    "        \n",
    "        df_suppliers = pd.read_sql_query(supplier_analysis_query, conn_string)\n",
    "        \n",
    "        supplier_doc = \"NORTHWIND SUPPLIER RELATIONSHIP AND LOGISTICS ANALYSIS:\\n\\n\"\n",
    "        \n",
    "        # Supplier overview\n",
    "        supplier_doc += f\"SUPPLIER NETWORK OVERVIEW:\\n\"\n",
    "        supplier_doc += f\"Total Suppliers: {len(df_suppliers)}\\n\"\n",
    "        supplier_doc += f\"Geographic Distribution: {len(df_suppliers['country'].unique())} countries\\n\"\n",
    "        supplier_doc += f\"Total Products Supplied: {df_suppliers['products_supplied'].sum()}\\n\"\n",
    "        supplier_doc += f\"Active Products: {df_suppliers['active_products'].sum()}\\n\\n\"\n",
    "        \n",
    "        # Supplier performance ranking\n",
    "        supplier_doc += \"TOP SUPPLIERS BY REVENUE GENERATION:\\n\"\n",
    "        for i, row in df_suppliers.head(15).iterrows():\n",
    "            region_info = f\", {row['region']}\" if pd.notna(row['region']) else \"\"\n",
    "            fax_info = f\", Fax: {row['fax']}\" if pd.notna(row['fax']) else \"\"\n",
    "            \n",
    "            supplier_doc += f\"{i+1}. {row['company_name']} ({row['country']})\\n\"\n",
    "            supplier_doc += f\"   • Contact: {row['contact_name']} ({row['contact_title']})\\n\"\n",
    "            supplier_doc += f\"   • Location: {row['city']}{region_info}\\n\"\n",
    "            supplier_doc += f\"   • Phone: {row['phone']}{fax_info}\\n\"\n",
    "            supplier_doc += f\"   • Products: {row['products_supplied']} total ({row['active_products']} active)\\n\"\n",
    "            supplier_doc += f\"   • Revenue Generated: ${row['total_revenue_generated']:,.2f}\\n\"\n",
    "            supplier_doc += f\"   • Units Sold: {row['total_units_sold']:,.0f}, Avg Product Price: ${row['avg_product_price']:,.2f}\\n\\n\"\n",
    "        \n",
    "        # Geographic supplier distribution\n",
    "        supplier_by_country = df_suppliers.groupby('country').agg({\n",
    "            'supplier_id': 'count',\n",
    "            'products_supplied': 'sum',\n",
    "            'total_revenue_generated': 'sum'\n",
    "        }).sort_values('total_revenue_generated', ascending=False)\n",
    "        \n",
    "        supplier_doc += \"SUPPLIER GEOGRAPHIC DISTRIBUTION:\\n\"\n",
    "        for country, row in supplier_by_country.iterrows():\n",
    "            avg_revenue_per_supplier = row['total_revenue_generated'] / row['supplier_id']\n",
    "            supplier_doc += f\"• {country}: {row['supplier_id']} suppliers, {row['products_supplied']} products, ${row['total_revenue_generated']:,.2f} revenue\\n\"\n",
    "            supplier_doc += f\"  Average revenue per supplier: ${avg_revenue_per_supplier:,.2f}\\n\"\n",
    "        \n",
    "        documents.append(supplier_doc)\n",
    "        \n",
    "        # 5. EMPLOYEE PERFORMANCE AND TERRITORY ANALYSIS\n",
    "        print(\"Generating employee and territory analysis...\")\n",
    "        \n",
    "        employee_analysis_query = f\"\"\"\n",
    "        WITH employee_performance AS (\n",
    "            SELECT \n",
    "                e.employee_id,\n",
    "                e.first_name || ' ' || e.last_name as full_name,\n",
    "                e.title,\n",
    "                e.title_of_courtesy,\n",
    "                e.birth_date,\n",
    "                e.hire_date,\n",
    "                e.city,\n",
    "                e.region,\n",
    "                e.country,\n",
    "                e.home_phone,\n",
    "                e.reports_to,\n",
    "                mgr.first_name || ' ' || mgr.last_name as manager_name,\n",
    "                COUNT(DISTINCT o.order_id) as orders_handled,\n",
    "                COUNT(DISTINCT o.customer_id) as customers_served,\n",
    "                COALESCE(ROUND(SUM(od.unit_price * od.quantity * (1 - od.discount))::numeric, 2), 0) as total_sales,\n",
    "                COALESCE(ROUND(AVG(od.unit_price * od.quantity * (1 - od.discount))::numeric, 2), 0) as avg_order_value,\n",
    "                COALESCE(SUM(od.quantity), 0) as total_units_sold,\n",
    "                COUNT(DISTINCT DATE_PART('year', o.order_date)) as years_active,\n",
    "                MIN(o.order_date) as first_sale_date,\n",
    "                MAX(o.order_date) as last_sale_date\n",
    "            FROM {schema}.employees e\n",
    "            LEFT JOIN {schema}.employees mgr ON e.reports_to = mgr.employee_id\n",
    "            LEFT JOIN {schema}.orders o ON e.employee_id = o.employee_id\n",
    "            LEFT JOIN {schema}.order_details od ON o.order_id = od.order_id\n",
    "            GROUP BY e.employee_id, e.first_name, e.last_name, e.title, e.title_of_courtesy,\n",
    "                     e.birth_date, e.hire_date, e.city, e.region, e.country, e.home_phone,\n",
    "                     e.reports_to, mgr.first_name, mgr.last_name\n",
    "        )\n",
    "        SELECT * FROM employee_performance\n",
    "        ORDER BY total_sales DESC\n",
    "        \"\"\"\n",
    "        \n",
    "        df_employees = pd.read_sql_query(employee_analysis_query, conn_string)\n",
    "        \n",
    "        employee_doc = \"NORTHWIND EMPLOYEE PERFORMANCE AND ORGANIZATIONAL ANALYSIS:\\n\\n\"\n",
    "        \n",
    "        # Organizational overview\n",
    "        employee_doc += f\"ORGANIZATIONAL STRUCTURE:\\n\"\n",
    "        employee_doc += f\"Total Employees: {len(df_employees)}\\n\"\n",
    "        \n",
    "        # Management hierarchy\n",
    "        managers = df_employees[df_employees['reports_to'].isna()]\n",
    "        subordinates = df_employees[df_employees['reports_to'].notna()]\n",
    "        \n",
    "        employee_doc += f\"Management Level: {len(managers)} managers\\n\"\n",
    "        employee_doc += f\"Staff Level: {len(subordinates)} employees\\n\\n\"\n",
    "        \n",
    "        # Employee performance ranking\n",
    "        employee_doc += \"EMPLOYEE SALES PERFORMANCE RANKING:\\n\"\n",
    "        for i, row in df_employees.iterrows():\n",
    "            manager_info = f\" (Reports to: {row['manager_name']})\" if pd.notna(row['manager_name']) else \" (Senior Management)\"\n",
    "            years_service = datetime.now().year - pd.to_datetime(row['hire_date']).year if pd.notna(row['hire_date']) else 0\n",
    "            age = datetime.now().year - pd.to_datetime(row['birth_date']).year if pd.notna(row['birth_date']) else 0\n",
    "            \n",
    "            employee_doc += f\"{i+1}. {row['full_name']} - {row['title']}\\n\"\n",
    "            employee_doc += f\"   • Total Sales: ${row['total_sales']:,.2f} across {row['orders_handled']} orders\\n\"\n",
    "            employee_doc += f\"   • Customers Served: {row['customers_served']}, Avg Order Value: ${row['avg_order_value']:,.2f}\\n\"\n",
    "            employee_doc += f\"   • Service Period: {years_service} years (hired {str(row['hire_date'])[:10]})\\n\"\n",
    "            employee_doc += f\"   • Age: {age}, Location: {row['city']}, {row['country']}\\n\"\n",
    "            employee_doc += f\"   • Contact: {row['home_phone']}{manager_info}\\n\\n\"\n",
    "        \n",
    "        # Performance metrics analysis\n",
    "        total_company_sales = df_employees['total_sales'].sum()\n",
    "        top_performer = df_employees.iloc[0]\n",
    "        \n",
    "        employee_doc += \"PERFORMANCE INSIGHTS:\\n\"\n",
    "        employee_doc += f\"• Top Performer: {top_performer['full_name']} (${top_performer['total_sales']:,.2f} - {(top_performer['total_sales']/total_company_sales*100):.1f}% of total sales)\\n\"\n",
    "        employee_doc += f\"• Average Sales per Employee: ${df_employees['total_sales'].mean():,.2f}\\n\"\n",
    "        employee_doc += f\"• Sales Performance Range: ${df_employees['total_sales'].min():,.2f} - ${df_employees['total_sales'].max():,.2f}\\n\"\n",
    "        employee_doc += f\"• Average Customer Base per Employee: {df_employees['customers_served'].mean():.1f} customers\\n\"\n",
    "        \n",
    "        documents.append(employee_doc)\n",
    "        \n",
    "        # 6. SHIPPING AND LOGISTICS ANALYSIS\n",
    "        print(\"Generating shipping and logistics analysis...\")\n",
    "        \n",
    "        shipping_analysis_query = f\"\"\"\n",
    "        WITH shipping_metrics AS (\n",
    "    SELECT \n",
    "        sh.shipper_id,\n",
    "        sh.company_name as shipper_name,\n",
    "        sh.phone as shipper_phone,\n",
    "        COUNT(o.order_id) as total_shipments,\n",
    "        COUNT(DISTINCT o.customer_id) as customers_served,\n",
    "        COUNT(DISTINCT o.ship_country) as countries_served,\n",
    "        ROUND(AVG(o.freight)::numeric, 2) as avg_freight_cost,\n",
    "        ROUND(SUM(o.freight)::numeric, 2) as total_freight_revenue,\n",
    "        ROUND(AVG((o.shipped_date::date - o.order_date::date))::numeric, 1) as avg_delivery_days,\n",
    "        COUNT(CASE WHEN o.shipped_date::date > o.required_date::date THEN 1 END) as late_deliveries,\n",
    "        ROUND((COUNT(CASE WHEN o.shipped_date::date > o.required_date::date THEN 1 END) * 100.0 / COUNT(o.order_id))::numeric, 2) as late_delivery_rate\n",
    "    FROM {schema}.shippers sh\n",
    "    LEFT JOIN {schema}.orders o ON sh.shipper_id = o.ship_via\n",
    "    WHERE o.shipped_date IS NOT NULL AND o.order_date IS NOT NULL\n",
    "    GROUP BY sh.shipper_id, sh.company_name, sh.phone\n",
    "),\n",
    "route_analysis AS (\n",
    "    SELECT \n",
    "        o.ship_country,\n",
    "        o.ship_city,\n",
    "        COUNT(o.order_id) as shipment_count,\n",
    "        ROUND(AVG(o.freight)::numeric, 2) as avg_freight_cost,\n",
    "        COUNT(DISTINCT o.customer_id) as customers_in_location\n",
    "    FROM {schema}.orders o\n",
    "    WHERE o.shipped_date IS NOT NULL\n",
    "    GROUP BY o.ship_country, o.ship_city\n",
    ")\n",
    "SELECT \n",
    "    sm.*,\n",
    "    (SELECT COUNT(*) FROM route_analysis) as total_shipping_locations\n",
    "FROM shipping_metrics sm\n",
    "ORDER BY sm.total_freight_revenue DESC;\n",
    "        \"\"\"\n",
    "        \n",
    "        df_shipping = pd.read_sql_query(shipping_analysis_query, conn_string)\n",
    "        \n",
    "        # Route analysis\n",
    "        route_query = f\"\"\"\n",
    "        SELECT \n",
    "            ship_country,\n",
    "            ship_city,\n",
    "            COUNT(order_id) as shipment_count,\n",
    "            ROUND(AVG(freight)::numeric, 2) as avg_freight_cost,\n",
    "            COUNT(DISTINCT customer_id) as customers_in_location\n",
    "        FROM {schema}.orders\n",
    "        WHERE shipped_date IS NOT NULL\n",
    "        GROUP BY ship_country, ship_city\n",
    "        ORDER BY shipment_count DESC\n",
    "        \"\"\"\n",
    "        \n",
    "        df_routes = pd.read_sql_query(route_query, conn_string)\n",
    "        \n",
    "        shipping_doc = \"NORTHWIND SHIPPING AND LOGISTICS PERFORMANCE ANALYSIS:\\n\\n\"\n",
    "        \n",
    "        # Shipping company performance\n",
    "        shipping_doc += \"SHIPPING PARTNER PERFORMANCE:\\n\"\n",
    "        for _, row in df_shipping.iterrows():\n",
    "            on_time_rate = 100 - row['late_delivery_rate']\n",
    "            \n",
    "            shipping_doc += f\"• {row['shipper_name']} (Phone: {row['shipper_phone']})\\n\"\n",
    "            shipping_doc += f\"  - Total Shipments: {row['total_shipments']:,} to {row['customers_served']} customers\\n\"\n",
    "            shipping_doc += f\"  - Coverage: {row['countries_served']} countries\\n\"\n",
    "            shipping_doc += f\"  - Freight Revenue: ${row['total_freight_revenue']:,.2f} (Avg: ${row['avg_freight_cost']:.2f} per shipment)\\n\"\n",
    "            shipping_doc += f\"  - Delivery Performance: {row['avg_delivery_days']:.1f} days average, {on_time_rate:.1f}% on-time rate\\n\"\n",
    "            shipping_doc += f\"  - Late Deliveries: {row['late_deliveries']} ({row['late_delivery_rate']:.1f}%)\\n\\n\"\n",
    "        \n",
    "        # Geographic shipping analysis\n",
    "        shipping_doc += \"TOP SHIPPING DESTINATIONS:\\n\"\n",
    "        country_routes = df_routes.groupby('ship_country').agg({\n",
    "            'shipment_count': 'sum',\n",
    "            'avg_freight_cost': 'mean',\n",
    "            'customers_in_location': 'sum',\n",
    "            'ship_city': 'count'\n",
    "        }).sort_values('shipment_count', ascending=False)\n",
    "        \n",
    "        for country, row in country_routes.head(15).iterrows():\n",
    "            shipping_doc += f\"• {country}: {row['shipment_count']} shipments to {row['ship_city']} cities\\n\"\n",
    "            shipping_doc += f\"  - {row['customers_in_location']} customers, avg freight: ${row['avg_freight_cost']:.2f}\\n\"\n",
    "        \n",
    "        shipping_doc += \"\\nTOP CITY DESTINATIONS:\\n\"\n",
    "        for _, row in df_routes.head(20).iterrows():\n",
    "            shipping_doc += f\"• {row['ship_city']}, {row['ship_country']}: {row['shipment_count']} shipments\\n\"\n",
    "            shipping_doc += f\"  - {row['customers_in_location']} customers, avg freight: ${row['avg_freight_cost']:.2f}\\n\"\n",
    "        \n",
    "        documents.append(shipping_doc)\n",
    "        \n",
    "        # 7. FINANCIAL PERFORMANCE AND TRENDS ANALYSIS\n",
    "        print(\"Generating comprehensive financial analysis...\")\n",
    "        \n",
    "        financial_analysis_query = f\"\"\"\n",
    "        WITH monthly_performance AS (\n",
    "            SELECT \n",
    "                EXTRACT(year FROM o.order_date) as year,\n",
    "                EXTRACT(month FROM o.order_date) as month,\n",
    "                COUNT(DISTINCT o.order_id) as order_count,\n",
    "                COUNT(DISTINCT o.customer_id) as active_customers,\n",
    "                COUNT(DISTINCT od.product_id) as products_sold,\n",
    "                SUM(od.quantity) as units_sold,\n",
    "                ROUND(SUM(od.unit_price * od.quantity * (1 - od.discount))::numeric, 2) as revenue,\n",
    "                ROUND(AVG(od.unit_price * od.quantity * (1 - od.discount))::numeric, 2) as avg_order_line_value,\n",
    "                ROUND(SUM(o.freight)::numeric, 2) as total_freight,\n",
    "                ROUND(SUM(od.unit_price * od.quantity * od.discount)::numeric, 2) as total_discounts,\n",
    "                ROUND(AVG(od.discount * 100)::numeric, 2) as avg_discount_percentage\n",
    "            FROM {schema}.orders o\n",
    "            JOIN {schema}.order_details od ON o.order_id = od.order_id\n",
    "            WHERE o.order_date IS NOT NULL\n",
    "            GROUP BY EXTRACT(year FROM o.order_date), EXTRACT(month FROM o.order_date)\n",
    "        ),\n",
    "        quarterly_performance AS (\n",
    "            SELECT \n",
    "                year,\n",
    "                CASE \n",
    "                    WHEN month IN (1,2,3) THEN 'Q1'\n",
    "                    WHEN month IN (4,5,6) THEN 'Q2'\n",
    "                    WHEN month IN (7,8,9) THEN 'Q3'\n",
    "                    ELSE 'Q4'\n",
    "                END as quarter,\n",
    "                SUM(order_count) as orders,\n",
    "                SUM(revenue) as quarterly_revenue,\n",
    "                AVG(active_customers) as avg_monthly_customers,\n",
    "                SUM(units_sold) as total_units,\n",
    "                SUM(total_freight) as freight_revenue\n",
    "            FROM monthly_performance\n",
    "            GROUP BY year, CASE \n",
    "                WHEN month IN (1,2,3) THEN 'Q1'\n",
    "                WHEN month IN (4,5,6) THEN 'Q2'\n",
    "                WHEN month IN (7,8,9) THEN 'Q3'\n",
    "                ELSE 'Q4'\n",
    "            END\n",
    "        )\n",
    "        SELECT * FROM monthly_performance\n",
    "        ORDER BY year, month\n",
    "        \"\"\"\n",
    "        \n",
    "        df_financial = pd.read_sql_query(financial_analysis_query, conn_string)\n",
    "        \n",
    "        financial_doc = \"NORTHWIND COMPREHENSIVE FINANCIAL PERFORMANCE ANALYSIS:\\n\\n\"\n",
    "        \n",
    "        # Overall financial summary\n",
    "        total_revenue = df_financial['revenue'].sum()\n",
    "        total_orders = df_financial['order_count'].sum()\n",
    "        total_discounts = df_financial['total_discounts'].sum()\n",
    "        \n",
    "        financial_doc += f\"FINANCIAL OVERVIEW:\\n\"\n",
    "        financial_doc += f\"• Total Revenue: ${total_revenue:,.2f}\\n\"\n",
    "        financial_doc += f\"• Total Orders: {total_orders:,}\\n\"\n",
    "        financial_doc += f\"• Total Discounts Given: ${total_discounts:,.2f} ({(total_discounts/total_revenue*100):.1f}% of revenue)\\n\"\n",
    "        financial_doc += f\"• Average Order Value: ${(total_revenue/total_orders):,.2f}\\n\"\n",
    "        financial_doc += f\"• Total Units Sold: {df_financial['units_sold'].sum():,}\\n\\n\"\n",
    "        \n",
    "        # Yearly performance\n",
    "        yearly_summary = df_financial.groupby('year').agg({\n",
    "            'revenue': 'sum',\n",
    "            'order_count': 'sum',\n",
    "            'active_customers': 'mean',\n",
    "            'units_sold': 'sum',\n",
    "            'total_freight': 'sum',\n",
    "            'total_discounts': 'sum'\n",
    "        }).round(2)\n",
    "        \n",
    "        financial_doc += \"ANNUAL PERFORMANCE BREAKDOWN:\\n\"\n",
    "        for year, row in yearly_summary.iterrows():\n",
    "            year_growth = \"\"\n",
    "            if year > yearly_summary.index.min():\n",
    "                prev_year_revenue = yearly_summary.loc[year-1, 'revenue']\n",
    "                growth_rate = ((row['revenue'] - prev_year_revenue) / prev_year_revenue * 100)\n",
    "                year_growth = f\" ({growth_rate:+.1f}% vs prior year)\"\n",
    "            \n",
    "            financial_doc += f\"• {int(year)}: ${row['revenue']:,.2f} revenue{year_growth}\\n\"\n",
    "            financial_doc += f\"  - {int(row['order_count']):,} orders from {row['active_customers']:.0f} avg monthly customers\\n\"\n",
    "            financial_doc += f\"  - {int(row['units_sold']):,} units sold, ${row['total_freight']:,.2f} freight revenue\\n\"\n",
    "            financial_doc += f\"  - ${row['total_discounts']:,.2f} in discounts ({(row['total_discounts']/row['revenue']*100):.1f}%)\\n\"\n",
    "        \n",
    "        # Monthly trends analysis\n",
    "        financial_doc += \"\\nMONTHLY PERFORMANCE TRENDS:\\n\"\n",
    "        month_names = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', \n",
    "                      'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "        \n",
    "        monthly_avg = df_financial.groupby('month').agg({\n",
    "            'revenue': 'mean',\n",
    "            'order_count': 'mean',\n",
    "            'active_customers': 'mean'\n",
    "        }).round(2)\n",
    "        \n",
    "        # Find best and worst performing months\n",
    "        best_month = monthly_avg['revenue'].idxmax()\n",
    "        worst_month = monthly_avg['revenue'].idxmin()\n",
    "        \n",
    "        financial_doc += f\"• Best Month: {month_names[int(best_month)-1]} (${monthly_avg.loc[best_month, 'revenue']:,.2f} avg revenue)\\n\"\n",
    "        financial_doc += f\"• Weakest Month: {month_names[int(worst_month)-1]} (${monthly_avg.loc[worst_month, 'revenue']:,.2f} avg revenue)\\n\"\n",
    "        financial_doc += f\"• Seasonal Variance: {((monthly_avg['revenue'].max() - monthly_avg['revenue'].min()) / monthly_avg['revenue'].mean() * 100):.1f}%\\n\\n\"\n",
    "        \n",
    "        financial_doc += \"MONTHLY AVERAGE PERFORMANCE:\\n\"\n",
    "        for month, row in monthly_avg.sort_values('revenue', ascending=False).iterrows():\n",
    "            month_name = month_names[int(month)-1]\n",
    "            financial_doc += f\"• {month_name}: ${row['revenue']:,.2f} revenue, {row['order_count']:.0f} orders, {row['active_customers']:.0f} customers\\n\"\n",
    "        \n",
    "        # Discount analysis\n",
    "        financial_doc += f\"\\nDISCOUNT STRATEGY ANALYSIS:\\n\"\n",
    "        financial_doc += f\"• Average Discount Rate: {df_financial['avg_discount_percentage'].mean():.1f}%\\n\"\n",
    "        financial_doc += f\"• Total Discount Impact: ${total_discounts:,.2f} ({(total_discounts/(total_revenue+total_discounts)*100):.1f}% of gross revenue)\\n\"\n",
    "        financial_doc += f\"• Revenue Recovery Ratio: {((total_revenue/total_discounts) if total_discounts > 0 else 0):.1f}:1\\n\"\n",
    "        \n",
    "        documents.append(financial_doc)\n",
    "        \n",
    "        # 8. ADVANCED BUSINESS INTELLIGENCE AND INSIGHTS\n",
    "        print(\"Generating advanced business intelligence insights...\")\n",
    "        \n",
    "        # Customer loyalty and retention analysis\n",
    "        loyalty_analysis_query = f\"\"\"\n",
    "WITH customer_behavior AS (\n",
    "    SELECT \n",
    "        c.customer_id,\n",
    "        c.company_name,\n",
    "        c.country,\n",
    "        COUNT(DISTINCT o.order_id) as total_orders,\n",
    "        COUNT(DISTINCT EXTRACT(year FROM o.order_date::date)) as years_active,\n",
    "        COUNT(DISTINCT EXTRACT(month FROM o.order_date::date)) as months_active,\n",
    "        MIN(o.order_date::date) as first_order,\n",
    "        MAX(o.order_date::date) as last_order,\n",
    "        SUM(od.quantity) as total_items,\n",
    "        COUNT(DISTINCT od.product_id) as product_variety,\n",
    "        ROUND(SUM(od.unit_price * od.quantity * (1 - od.discount))::numeric, 2) as total_spent,\n",
    "        -- Calculate customer lifetime in days instead\n",
    "        MAX(o.order_date::date) - MIN(o.order_date::date) as customer_lifetime_days\n",
    "    FROM northwind.customers c\n",
    "    JOIN northwind.orders o ON c.customer_id = o.customer_id\n",
    "    JOIN northwind.order_details od ON o.order_id = od.order_id\n",
    "    WHERE o.order_date IS NOT NULL\n",
    "    GROUP BY c.customer_id, c.company_name, c.country\n",
    ")\n",
    "SELECT *,\n",
    "    CASE \n",
    "        WHEN total_orders >= 10 AND years_active >= 2 THEN 'Loyal'\n",
    "        WHEN total_orders >= 5 AND years_active >= 1 THEN 'Regular'\n",
    "        WHEN total_orders >= 3 THEN 'Developing'\n",
    "        ELSE 'New'\n",
    "    END as customer_segment,\n",
    "    -- Calculate average days between orders as total lifetime / (orders - 1)\n",
    "    CASE \n",
    "        WHEN total_orders > 1 THEN ROUND((customer_lifetime_days::numeric / (total_orders - 1)), 1)\n",
    "        ELSE NULL\n",
    "    END as avg_days_between_orders\n",
    "FROM customer_behavior\n",
    "ORDER BY total_spent DESC;\n",
    "        \"\"\"\n",
    "        \n",
    "        df_loyalty = pd.read_sql_query(loyalty_analysis_query, conn_string)\n",
    "        \n",
    "        # Product affinity analysis\n",
    "        affinity_query = f\"\"\"\n",
    "        WITH product_pairs AS (\n",
    "            SELECT \n",
    "                od1.product_id as product_a,\n",
    "                od2.product_id as product_b,\n",
    "                COUNT(*) as co_occurrence\n",
    "            FROM {schema}.order_details od1\n",
    "            JOIN {schema}.order_details od2 ON od1.order_id = od2.order_id\n",
    "            WHERE od1.product_id < od2.product_id\n",
    "            GROUP BY od1.product_id, od2.product_id\n",
    "            HAVING COUNT(*) >= 3\n",
    "        )\n",
    "        SELECT \n",
    "            pp.product_a,\n",
    "            p1.product_name as product_a_name,\n",
    "            pp.product_b,\n",
    "            p2.product_name as product_b_name,\n",
    "            pp.co_occurrence\n",
    "        FROM product_pairs pp\n",
    "        JOIN {schema}.products p1 ON pp.product_a = p1.product_id\n",
    "        JOIN {schema}.products p2 ON pp.product_b = p2.product_id\n",
    "        ORDER BY pp.co_occurrence DESC\n",
    "        LIMIT 20\n",
    "        \"\"\"\n",
    "        \n",
    "        df_affinity = pd.read_sql_query(affinity_query, conn_string)\n",
    "        \n",
    "        insights_doc = \"NORTHWIND ADVANCED BUSINESS INTELLIGENCE AND STRATEGIC INSIGHTS:\\n\\n\"\n",
    "        \n",
    "        # Customer segmentation analysis\n",
    "        segment_analysis = df_loyalty['customer_segment'].value_counts()\n",
    "        \n",
    "        insights_doc += \"CUSTOMER LOYALTY SEGMENTATION:\\n\"\n",
    "        for segment, count in segment_analysis.items():\n",
    "            segment_customers = df_loyalty[df_loyalty['customer_segment'] == segment]\n",
    "            avg_spend = segment_customers['total_spent'].mean()\n",
    "            avg_orders = segment_customers['total_orders'].mean()\n",
    "            \n",
    "            insights_doc += f\"• {segment} Customers: {count} ({(count/len(df_loyalty)*100):.1f}%)\\n\"\n",
    "            insights_doc += f\"  - Average Spend: ${avg_spend:,.2f}\\n\"\n",
    "            insights_doc += f\"  - Average Orders: {avg_orders:.1f}\\n\"\n",
    "            insights_doc += f\"  - Example: {segment_customers.iloc[0]['company_name']}\\n\"\n",
    "        \n",
    "        # High-value customer analysis\n",
    "        insights_doc += \"\\nHIGH-VALUE CUSTOMER PROFILE:\\n\"\n",
    "        top_customers = df_loyalty.head(10)\n",
    "        insights_doc += f\"• Top 10 customers represent ${top_customers['total_spent'].sum():,.2f} ({(top_customers['total_spent'].sum()/df_loyalty['total_spent'].sum()*100):.1f}% of total revenue)\\n\"\n",
    "        insights_doc += f\"• Average order frequency: {top_customers['avg_days_between_orders'].mean():.0f} days between orders\\n\"\n",
    "        insights_doc += f\"• Product diversity: {top_customers['product_variety'].mean():.0f} different products per customer\\n\"\n",
    "        \n",
    "        insights_doc += \"\\nTOP 10 MOST VALUABLE CUSTOMERS:\\n\"\n",
    "        for i, row in top_customers.iterrows():\n",
    "            customer_tenure = f\"{row['first_order']:.10} to {row['last_order']:.10}\"\n",
    "            insights_doc += f\"{i+1}. {row['company_name']} ({row['country']})\\n\"\n",
    "            insights_doc += f\"   • Total Value: ${row['total_spent']:,.2f} over {row['total_orders']} orders\\n\"\n",
    "            insights_doc += f\"   • Tenure: {customer_tenure} ({row['years_active']} years)\\n\"\n",
    "            insights_doc += f\"   • Behavior: {row['product_variety']} different products, avg {row['avg_days_between_orders']:.0f} days between orders\\n\"\n",
    "            insights_doc += f\"   • Segment: {row['customer_segment']}\\n\\n\"\n",
    "        \n",
    "        # Product affinity insights\n",
    "        insights_doc += \"PRODUCT AFFINITY ANALYSIS (Frequently Bought Together):\\n\"\n",
    "        insights_doc += \"Products commonly purchased together can inform cross-selling strategies:\\n\\n\"\n",
    "        \n",
    "        for i, row in df_affinity.head(15).iterrows():\n",
    "            insights_doc += f\"• {row['product_a_name']} + {row['product_b_name']}\\n\"\n",
    "            insights_doc += f\"  Purchased together in {row['co_occurrence']} orders\\n\"\n",
    "        \n",
    "        # Business recommendations\n",
    "        insights_doc += \"\\nSTRATEGIC BUSINESS RECOMMENDATIONS:\\n\"\n",
    "        \n",
    "        # Revenue concentration analysis\n",
    "        top_20_pct_customers = len(df_loyalty) // 5\n",
    "        top_20_revenue = df_loyalty.head(top_20_pct_customers)['total_spent'].sum()\n",
    "        total_revenue_check = df_loyalty['total_spent'].sum()\n",
    "        \n",
    "        insights_doc += f\"• Revenue Concentration: Top 20% of customers generate ${top_20_revenue:,.2f} ({(top_20_revenue/total_revenue_check*100):.1f}% of revenue)\\n\"\n",
    "        insights_doc += f\"• Customer Retention: Focus on {segment_analysis['Loyal']} loyal customers who drive consistent revenue\\n\"\n",
    "        insights_doc += f\"• Growth Opportunity: {segment_analysis['Developing']} developing customers show potential for increased engagement\\n\"\n",
    "        \n",
    "        # Seasonal insights\n",
    "        peak_months = df_financial.groupby('month')['revenue'].mean().nlargest(3)\n",
    "        insights_doc += f\"• Seasonal Strategy: Peak sales months are {', '.join([month_names[int(m)-1] for m in peak_months.index])}\\n\"\n",
    "        \n",
    "        # Geographic insights\n",
    "        country_performance = df_loyalty.groupby('country').agg({\n",
    "            'total_spent': 'sum',\n",
    "            'customer_id': 'count'\n",
    "        }).sort_values('total_spent', ascending=False)\n",
    "        \n",
    "        top_country = country_performance.index[0]\n",
    "        insights_doc += f\"• Geographic Focus: {top_country} is the top market with ${country_performance.loc[top_country, 'total_spent']:,.2f} from {country_performance.loc[top_country, 'customer_id']} customers\\n\"\n",
    "        \n",
    "        documents.append(insights_doc)\n",
    "# /*        \n",
    "#         # 9. OPERATIONAL EFFICIENCY AND INVENTORY INSIGHTS\n",
    "#         print(\"Generating operational efficiency analysis...\")\n",
    "        \n",
    "#         operational_query = f\"\"\"\n",
    "#         WITH order_processing AS (\n",
    "#         SELECT \n",
    "#             o.order_id,\n",
    "#             o.customer_id,\n",
    "#             o.employee_id,\n",
    "#             o.order_date::date,\n",
    "#             o.required_date::date,\n",
    "#             o.shipped_date::date,\n",
    "#             (o.shipped_date::date - o.order_date::date) as processing_days,\n",
    "#             (o.required_date::date - o.order_date::date) as promised_delivery_days,\n",
    "#             CASE WHEN o.shipped_date::date > o.required_date::date THEN 1 ELSE 0 END as late_delivery,\n",
    "#             o.freight,\n",
    "#             o.ship_country,\n",
    "#             COUNT(od.product_id) as items_in_order,\n",
    "#             SUM(od.quantity) as total_quantity,\n",
    "#             ROUND(SUM(od.unit_price * od.quantity * (1 - od.discount))::numeric, 2) as order_value\n",
    "#         FROM {schema}.orders o\n",
    "#         JOIN {schema}.order_details od ON o.order_id = od.order_id\n",
    "#         WHERE o.shipped_date IS NOT NULL AND o.order_date IS NOT NULL\n",
    "#         GROUP BY o.order_id, o.customer_id, o.employee_id, o.order_date, o.required_date, o.shipped_date, o.freight, o.ship_country\n",
    "#         ),\n",
    "#         inventory_turnover AS (\n",
    "#         SELECT \n",
    "#             p.product_id,\n",
    "#             p.product_name,\n",
    "#             c.category_name,\n",
    "#             p.units_in_stock,\n",
    "#             p.units_on_order,\n",
    "#             p.reorder_level,\n",
    "#             COALESCE(SUM(od.quantity), 0) as total_sold,\n",
    "#             CASE \n",
    "#             WHEN p.units_in_stock > 0 THEN ROUND((COALESCE(SUM(od.quantity), 0)::numeric / p.units_in_stock), 2)\n",
    "#             ELSE 0 \n",
    "#             END as turnover_ratio\n",
    "#         FROM {schema}.products p\n",
    "#         JOIN {schema}.categories c ON p.category_id = c.category_id\n",
    "#         LEFT JOIN {schema}.order_details od ON p.product_id = od.product_id\n",
    "#         WHERE p.discontinued = 0\n",
    "#         GROUP BY p.product_id, p.product_name, c.category_name, p.units_in_stock, p.units_on_order, p.reorder_level\n",
    "#         )\n",
    "#         SELECT \n",
    "#         'processing' as analysis_type,\n",
    "#         ROUND(AVG(processing_days)::numeric, 1) as avg_processing_days,\n",
    "#         ROUND(AVG(promised_delivery_days)::numeric, 1) as avg_promised_days,\n",
    "#         SUM(late_delivery) as total_late_deliveries,\n",
    "#         COUNT(*) as total_orders,\n",
    "#         ROUND(AVG(freight)::numeric, 2) as avg_freight_cost\n",
    "#         FROM order_processing\n",
    "\n",
    "#         UNION ALL\n",
    "\n",
    "#         SELECT \n",
    "#         'inventory' as analysis_type,\n",
    "#         ROUND(AVG(turnover_ratio)::numeric, 2) as avg_turnover,\n",
    "#         COUNT(CASE WHEN units_in_stock <= reorder_level THEN 1 END)::numeric as low_stock_items,\n",
    "#         COUNT(*)::numeric as total_active_products,\n",
    "#         SUM(units_in_stock)::numeric as total_inventory_units,\n",
    "#         ROUND(AVG(units_in_stock)::numeric, 1) as avg_stock_per_product\n",
    "#         FROM inventory_turnover; \"\"\"\n",
    "\n",
    "#         df_operational = pd.read_sql_query(operational_query, conn_string)\n",
    "        \n",
    "        \n",
    "#         # Detailed inventory analysis\n",
    "#         inventory_detail_query = f\"\"\"\n",
    "#         SELECT \n",
    "#             p.product_name,\n",
    "#             c.category_name,\n",
    "#             p.units_in_stock,\n",
    "#             p.reorder_level,\n",
    "#             p.units_on_order,\n",
    "#             COALESCE(SUM(od.quantity), 0) as units_sold,\n",
    "#             CASE \n",
    "#                 WHEN p.units_in_stock > 0 AND COALESCE(SUM(od.quantity), 0) > 0\n",
    "#                 THEN ROUND((COALESCE(SUM(od.quantity), 0) / p.units_in_stock)::numeric, 2)\n",
    "#                 ELSE 0 \n",
    "#             END as turnover_ratio,\n",
    "#             CASE \n",
    "#                 WHEN p.units_in_stock <= p.reorder_level THEN 'LOW STOCK'\n",
    "#                 WHEN p.units_in_stock = 0 THEN 'OUT OF STOCK'\n",
    "#                 WHEN p.units_in_stock > p.reorder_level * 3 THEN 'OVERSTOCK'\n",
    "#                 ELSE 'NORMAL'\n",
    "#             END as stock_status\n",
    "#         FROM {schema}.products p\n",
    "#         JOIN {schema}.categories c ON p.category_id = c.category_id\n",
    "#         LEFT JOIN {schema}.order_details od ON p.product_id = od.product_id\n",
    "#         WHERE p.discontinued = 0\n",
    "#         GROUP BY p.product_id, p.product_name, c.category_name, \n",
    "#                  p.units_in_stock, p.reorder_level, p.units_on_order\n",
    "#         ORDER BY turnover_ratio DESC\n",
    "#         \"\"\"\n",
    "        \n",
    "#         df_inventory_detail = pd.read_sql_query(inventory_detail_query, conn_string)\n",
    "        \n",
    "#         operational_doc = \"NORTHWIND OPERATIONAL EFFICIENCY AND INVENTORY MANAGEMENT ANALYSIS:\\n\\n\"\n",
    "        \n",
    "#         # Extract operational metrics\n",
    "#         processing_metrics = df_operational[df_operational['analysis_type'] == 'processing'].iloc[0]\n",
    "#         inventory_metrics = df_operational[df_operational['analysis_type'] == 'inventory'].iloc[0]\n",
    "\n",
    "#         operational_doc += \"ORDER PROCESSING EFFICIENCY:\\n\"\n",
    "#         operational_doc += f\"• Average Processing Time: {processing_metrics['avg_processing_days']:.1f} days\\n\"\n",
    "#         operational_doc += f\"• Average Promised Delivery: {processing_metrics['avg_promised_days']:.1f} days\\n\"\n",
    "#         operational_doc += f\"• Late Deliveries: {processing_metrics['total_late_deliveries']:.0f} out of {processing_metrics['total_orders']:.0f} orders\\n\"\n",
    "#         operational_doc += f\"• Average Freight Cost: ${processing_metrics['avg_freight_cost']:.2f} per shipment\\n\\n\"\n",
    "\n",
    "#         operational_doc += \"INVENTORY MANAGEMENT PERFORMANCE:\\n\"\n",
    "#         operational_doc += f\"• Average Inventory Turnover Ratio: {inventory_metrics['avg_turnover']:.2f}\\n\"\n",
    "#         operational_doc += f\"• Products Below Reorder Level: {inventory_metrics['low_stock_items']:.0f} out of {inventory_metrics['total_active_products']:.0f}\\n\"\n",
    "#         operational_doc += f\"• Total Inventory Units: {inventory_metrics['total_inventory_units']:.0f}\\n\"\n",
    "#         operational_doc += f\"• Average Stock per Product: {inventory_metrics['avg_stock_per_product']:.0f} units\\n\\n\"        \n",
    "#         # Stock status analysis\n",
    "#         stock_status_summary = df_inventory_detail['stock_status'].value_counts()\n",
    "        \n",
    "#         operational_doc += \"INVENTORY STATUS BREAKDOWN:\\n\"\n",
    "#         for status, count in stock_status_summary.items():\n",
    "#             operational_doc += f\"• {status}: {count} products ({(count/len(df_inventory_detail)*100):.1f}%)\\n\"\n",
    "        \n",
    "#         # Critical inventory alerts\n",
    "#         critical_items = df_inventory_detail[df_inventory_detail['stock_status'].isin(['LOW STOCK', 'OUT OF STOCK'])]\n",
    "#         high_turnover_critical = critical_items[critical_items['turnover_ratio'] > inventory_metrics['avg_turnover']]\n",
    "        \n",
    "#         operational_doc += f\"\\nCRITICAL INVENTORY ALERTS:\\n\"\n",
    "#         operational_doc += f\"• Items Needing Immediate Attention: {len(critical_items)}\\n\"\n",
    "#         operational_doc += f\"• High-Demand Items with Low Stock: {len(high_turnover_critical)}\\n\"\n",
    "        \n",
    "#         if len(high_turnover_critical) > 0:\n",
    "#             operational_doc += \"\\nURGENT REORDER RECOMMENDATIONS:\\n\"\n",
    "#             for _, item in high_turnover_critical.head(10).iterrows():\n",
    "#                 operational_doc += f\"• {item['product_name']} ({item['category_name']})\\n\"\n",
    "#                 operational_doc += f\"  - Current Stock: {item['units_in_stock']}, Reorder Level: {item['reorder_level']}\\n\"\n",
    "#                 operational_doc += f\"  - Turnover Ratio: {item['turnover_ratio']:.2f}, On Order: {item['units_on_order']}\\n\"\n",
    "        \n",
    "#         # Best performing inventory\n",
    "#         operational_doc += \"\\nTOP PERFORMING PRODUCTS (by turnover):\\n\"\n",
    "#         top_performers = df_inventory_detail[df_inventory_detail['turnover_ratio'] > 0].head(15)\n",
    "#         for _, item in top_performers.iterrows():\n",
    "#             operational_doc += f\"• {item['product_name']}: {item['turnover_ratio']:.2f} turnover ratio\\n\"\n",
    "#             operational_doc += f\"  - Stock: {item['units_in_stock']}, Sold: {item['units_sold']}, Status: {item['stock_status']}\\n\"\n",
    "        \n",
    "#         documents.append(operational_doc)\n",
    "        \n",
    "        print(f\"Successfully created {len(documents)} comprehensive business documents from Northwind PostgreSQL database\")\n",
    "        print(f\"Total document length: {sum(len(doc) for doc in documents):,} characters\")\n",
    "        \n",
    "        return documents\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error creating comprehensive documents: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return []\n",
    "\n",
    "# # Usage example:\n",
    "# if __name__ == \"__main__\":\n",
    "#     # Neon PostgreSQL connection parameters\n",
    "#     business_docs = create_comprehensive_northwind_business_documents(\n",
    "#         host=\"ep-xxx-xxx.us-east-1.aws.neon.tech\",  # Your Neon host\n",
    "#         username=\"your_username\",\n",
    "#         password=\"your_password\",\n",
    "#         database=\"neondb\",\n",
    "#         port=5432,\n",
    "#         schema=\"northwind\"\n",
    "#     )\n",
    "    \n",
    "#     # Preview the documents\n",
    "#     for i, doc in enumerate(business_docs):\n",
    "#         print(f\"\\n{'='*80}\")\n",
    "#         print(f\"DOCUMENT {i+1}: {['CUSTOMER ANALYSIS', 'CUSTOMER BEHAVIOR', 'PRODUCT CATALOG', 'SUPPLIER ANALYSIS', 'EMPLOYEE PERFORMANCE', 'SHIPPING LOGISTICS', 'FINANCIAL PERFORMANCE', 'BUSINESS INTELLIGENCE', 'OPERATIONAL EFFICIENCY'][i]}\")\n",
    "#         print('='*80)\n",
    "#         print(doc[:1000] + \"...\" if len(doc) > 1000 else doc)\n",
    "    \n",
    "    # Integration with vector store\n",
    "    \"\"\"\n",
    "    from langchain.schema import Document\n",
    "    \n",
    "    # Convert to LangChain documents with detailed metadata\n",
    "    langchain_docs = []\n",
    "    doc_types = [\n",
    "        \"customer_analysis\", \"customer_behavior\", \"product_catalog\", \n",
    "        \"supplier_analysis\", \"employee_performance\", \"shipping_logistics\",\n",
    "        \"financial_performance\", \"business_intelligence\", \"operational_efficiency\"\n",
    "    ]\n",
    "    \n",
    "    for i, doc in enumerate(business_docs):\n",
    "        langchain_docs.append(Document(\n",
    "            page_content=doc,\n",
    "            metadata={\n",
    "                \"source\": f\"northwind_comprehensive_{doc_types[i]}\",\n",
    "                \"type\": \"business_analysis\",\n",
    "                \"document_id\": i,\n",
    "                \"comprehensive\": True,\n",
    "                \"data_source\": \"postgresql_neon\"\n",
    "            }\n",
    "        ))\n",
    "    \n",
    "    # Enhanced text splitting for comprehensive documents\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=600,  # Larger chunks for comprehensive content\n",
    "        chunk_overlap=100,  # More overlap for context preservation\n",
    "        length_function=tiktoken_len,\n",
    "    )\n",
    "    \n",
    "    split_chunks = text_splitter.split_documents(langchain_docs)\n",
    "    \n",
    "    # Create vector store\n",
    "    qdrant_vectorstore = Qdrant.from_documents(\n",
    "        split_chunks,\n",
    "        embedding_model,\n",
    "        location=\":memory:\",\n",
    "        collection_name=\"northwind_comprehensive_business_data\",\n",
    "    )\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to Northwind database and generating comprehensive business documents...\n",
      "Generating customer analysis document...\n",
      "Generating customer purchasing behavior analysis...\n",
      "Generating comprehensive product analysis...\n",
      "Generating supplier analysis...\n",
      "Generating employee and territory analysis...\n",
      "Generating shipping and logistics analysis...\n",
      "Generating comprehensive financial analysis...\n",
      "Generating advanced business intelligence insights...\n",
      "Successfully created 8 comprehensive business documents from Northwind PostgreSQL database\n",
      "Total document length: 37,030 characters\n"
     ]
    }
   ],
   "source": [
    "# # Or with custom database/schema\n",
    "business_docs = create_comprehensive_northwind_business_documents(\n",
    "    host=\"ep-aged-leaf-a5sdyft6-pooler.us-east-2.aws.neon.tech\",\n",
    "    username=\"neondb_owner\",\n",
    "    password=\"npg_m5bUF7retyMH\",\n",
    "    database=\"neondb\",\n",
    "    schema=\"northwind\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
