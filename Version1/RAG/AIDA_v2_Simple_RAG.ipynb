{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple RAG System with PDF Section-Based Chunking\n",
    "\n",
    "# This notebook implements a streamlined RAG system with:\n",
    "# 1. PDF section-based chunking using tiktoken\n",
    "# 2. OpenAI embeddings\n",
    "# 3. Qdrant vector store\n",
    "# 4. Score-filtered retriever\n",
    "# 5. Simple RAG chain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages if needed\n",
    "# !pip install -qU langchain==0.2.14 langchain_openai==0.1.23 langchain_core==0.2.35 langchain-community\n",
    "# !pip install -qU qdrant-client pymupdf tiktoken\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "\n",
    "# Set up OpenAI API key\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OpenAI API Key:\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 1. PDF Section-Based Chunking\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî¢ Available Tiktoken Encodings:\n",
      "   cl100k_base: GPT-4, GPT-3.5-turbo, text-embedding-ada-002\n",
      "   p50k_base: text-davinci-002, text-davinci-003\n",
      "   r50k_base: GPT-3 models (davinci, curie, babbage, ada)\n",
      "   gpt2: GPT-2 models\n"
     ]
    }
   ],
   "source": [
    "# Import the PDF section chunker\n",
    "from pdf_section_chunker import chunk_northwind_pdf, get_encoding_info, TIKTOKEN_AVAILABLE\n",
    "\n",
    "# Show available encodings\n",
    "if TIKTOKEN_AVAILABLE:\n",
    "    print(\"üî¢ Available Tiktoken Encodings:\")\n",
    "    for encoding, models in get_encoding_info().items():\n",
    "        print(f\"   {encoding}: {models}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Tiktoken not available - using character-based chunking\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Processing Northwind_Traders_Database_Overview.pdf...\n",
      "‚úì Using token-based chunking with cl100k_base encoding\n",
      "‚úÖ Created 34 intelligent chunks from the PDF\n",
      "\n",
      "üìä Chunk Statistics:\n",
      "   Character count - Min: 159, Max: 2049, Avg: 1257\n",
      "   Token count - Min: 34, Max: 396, Avg: 248\n",
      "   Chunking method: tokens\n",
      "   Encoding: cl100k_base\n"
     ]
    }
   ],
   "source": [
    "# Process the Northwind PDF with intelligent section-based chunking\n",
    "print(\"üîÑ Processing Northwind_Traders_Database_Overview.pdf...\")\n",
    "\n",
    "# Create chunks using our advanced PDF section chunker\n",
    "chunks = chunk_northwind_pdf(\n",
    "    pdf_path=\"data/Northwind_Traders_Database_Overview.pdf\",\n",
    "    use_tokens=True,\n",
    "    encoding_name=\"cl100k_base\"  # Optimal for OpenAI models\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Created {len(chunks)} intelligent chunks from the PDF\")\n",
    "\n",
    "# Display statistics\n",
    "if chunks:\n",
    "    char_counts = [chunk.metadata.get('char_count', len(chunk.content)) for chunk in chunks]\n",
    "    token_counts = [chunk.metadata.get('token_count', 0) for chunk in chunks]\n",
    "    \n",
    "    print(f\"\\nüìä Chunk Statistics:\")\n",
    "    print(f\"   Character count - Min: {min(char_counts)}, Max: {max(char_counts)}, Avg: {sum(char_counts)//len(char_counts)}\")\n",
    "    \n",
    "    if any(token_counts):\n",
    "        print(f\"   Token count - Min: {min(token_counts)}, Max: {max(token_counts)}, Avg: {sum(token_counts)//len(token_counts)}\")\n",
    "        print(f\"   Chunking method: {chunks[0].metadata.get('chunking_method', 'unknown')}\")\n",
    "        print(f\"   Encoding: {chunks[0].metadata.get('encoding', 'N/A')}\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 2. Convert to LangChain Documents\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 2.5. Generate Database Documents\n",
    "\n",
    "Let's also create comprehensive business documents from the Northwind database to enrich our knowledge base.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the database document creation function\n",
    "from Create_RAG_docs_from_db import create_comprehensive_northwind_business_documents\n",
    "\n",
    "# Generate comprehensive business documents from database\n",
    "print(\"üîÑ Generating comprehensive business documents from Northwind database...\")\n",
    "\n",
    "try:\n",
    "    # Database connection parameters (update these with your credentials)\n",
    "    business_docs = create_comprehensive_northwind_business_documents(\n",
    "        host=\"ep-aged-leaf-a5sdyft6-pooler.us-east-2.aws.neon.tech\",\n",
    "        username=\"neondb_owner\",\n",
    "        password=\"npg_m5bUF7retyMH\", \n",
    "        database=\"neondb\",\n",
    "        schema=\"northwind\"\n",
    "    )\n",
    "    \n",
    "    print(f\"‚úÖ Generated {len(business_docs)} comprehensive business documents\")\n",
    "    print(f\"üìÑ Total content length: {sum(len(doc) for doc in business_docs):,} characters\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Could not connect to database: {e}\")\n",
    "    print(\"üìù Using empty list for business documents - PDF documents will still work\")\n",
    "    business_docs = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert database documents to LangChain format\n",
    "def convert_business_docs_to_langchain(business_docs):\n",
    "    \"\"\"Convert database business documents to LangChain Document format.\"\"\"\n",
    "    langchain_docs = []\n",
    "    \n",
    "    # Document type mapping for better metadata\n",
    "    doc_types = [\n",
    "        \"customer_analysis\", \"customer_behavior\", \"product_catalog\", \n",
    "        \"supplier_analysis\", \"employee_performance\", \"shipping_logistics\",\n",
    "        \"financial_performance\", \"business_intelligence\", \"operational_efficiency\"\n",
    "    ]\n",
    "    \n",
    "    for i, doc in enumerate(business_docs):\n",
    "        # Create descriptive metadata\n",
    "        doc_type = doc_types[i] if i < len(doc_types) else f\"business_doc_{i}\"\n",
    "        \n",
    "        # Create LangChain Document\n",
    "        langchain_doc = Document(\n",
    "            page_content=doc,\n",
    "            metadata={\n",
    "                \"source\": f\"northwind_database_{doc_type}\",\n",
    "                \"type\": \"business_analysis\",\n",
    "                \"document_id\": i,\n",
    "                \"comprehensive\": True,\n",
    "                \"data_source\": \"postgresql_database\",\n",
    "                \"section_title\": doc_type.replace('_', ' ').title(),\n",
    "                \"section_level\": 1,\n",
    "                \"char_count\": len(doc),\n",
    "                \"chunk_type\": \"database_generated\"\n",
    "            }\n",
    "        )\n",
    "        langchain_docs.append(langchain_doc)\n",
    "    \n",
    "    return langchain_docs\n",
    "\n",
    "# Convert business documents to LangChain format\n",
    "db_documents = convert_business_docs_to_langchain(business_docs)\n",
    "\n",
    "print(f\"üìö Converted {len(db_documents)} database documents to LangChain format\")\n",
    "\n",
    "# Display sample metadata from database documents\n",
    "if db_documents:\n",
    "    print(f\"üìÑ Sample DB metadata: {db_documents[0].metadata}\")\n",
    "else:\n",
    "    print(\"üìù No database documents to convert\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìö Converted 34 chunks to LangChain Document format\n",
      "üìÑ Sample metadata: {'source': 'data/Northwind_Traders_Database_Overview.pdf', 'page': 1, 'section_title': 'Northwind Traders Database Overview', 'section_level': 1, 'char_count': 427, 'token_count': 77, 'chunking_method': 'tokens', 'encoding': 'cl100k_base', 'chunk_type': 'section', 'is_split': False}\n"
     ]
    }
   ],
   "source": [
    "# Convert our DocumentChunk objects to LangChain Document format\n",
    "from langchain.schema import Document\n",
    "\n",
    "def convert_chunks_to_langchain_docs(chunks):\n",
    "    \"\"\"Convert our DocumentChunk objects to LangChain Document format.\"\"\"\n",
    "    langchain_docs = []\n",
    "    \n",
    "    for chunk in chunks:\n",
    "        # Create metadata that includes all our enhanced information\n",
    "        metadata = {\n",
    "            \"source\": chunk.metadata.get('source', 'Northwind_Traders_Database_Overview.pdf'),\n",
    "            \"page\": chunk.page_number,\n",
    "            \"section_title\": chunk.title,\n",
    "            \"section_level\": chunk.section_level,\n",
    "            \"char_count\": chunk.metadata.get('char_count', len(chunk.content)),\n",
    "            \"token_count\": chunk.metadata.get('token_count', 0),\n",
    "            \"chunking_method\": chunk.metadata.get('chunking_method', 'unknown'),\n",
    "            \"encoding\": chunk.metadata.get('encoding', 'N/A'),\n",
    "            \"chunk_type\": chunk.metadata.get('chunk_type', 'section'),\n",
    "            \"is_split\": chunk.metadata.get('is_split', False)\n",
    "        }\n",
    "        \n",
    "        # Create LangChain Document\n",
    "        doc = Document(\n",
    "            page_content=chunk.content,\n",
    "            metadata=metadata\n",
    "        )\n",
    "        langchain_docs.append(doc)\n",
    "    \n",
    "    return langchain_docs\n",
    "\n",
    "# Convert our smart chunks to LangChain format\n",
    "pdf_documents = convert_chunks_to_langchain_docs(chunks)\n",
    "\n",
    "# Combine PDF and database documents\n",
    "all_documents = pdf_documents + db_documents\n",
    "\n",
    "print(f\"üìö Combined Documents Summary:\")\n",
    "print(f\"   ‚Ä¢ PDF chunks: {len(pdf_documents)} documents\")\n",
    "print(f\"   ‚Ä¢ Database docs: {len(db_documents)} documents\") \n",
    "print(f\"   ‚Ä¢ Total documents: {len(all_documents)} documents\")\n",
    "\n",
    "# Display sample metadata from both sources\n",
    "if pdf_documents:\n",
    "    print(f\"üìÑ Sample PDF metadata: {pdf_documents[0].metadata}\")\n",
    "if db_documents:\n",
    "    print(f\"üìÑ Sample DB metadata: {db_documents[0].metadata}\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 3. Create OpenAI Embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Initialized OpenAI embeddings model\n"
     ]
    }
   ],
   "source": [
    "# Initialize OpenAI embeddings\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "\n",
    "embedding_model = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "print(\"‚úÖ Initialized OpenAI embeddings model\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 4. Create Qdrant Vector Store\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Created Qdrant vector store with 34 documents\n"
     ]
    }
   ],
   "source": [
    "# Create Qdrant vector store in memory with all documents\n",
    "from langchain_community.vectorstores import Qdrant\n",
    "\n",
    "# We may need to split large database documents for better retrieval\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Split large database documents while keeping PDF chunks intact\n",
    "def smart_split_documents(all_documents):\n",
    "    \"\"\"Split only large database documents while preserving PDF chunks.\"\"\"\n",
    "    final_documents = []\n",
    "    \n",
    "    # Text splitter for large documents only\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=1500,  # Reasonable size for database docs\n",
    "        chunk_overlap=200,\n",
    "        length_function=len,\n",
    "    )\n",
    "    \n",
    "    for doc in all_documents:\n",
    "        # If it's a large database document, split it\n",
    "        if doc.metadata.get('data_source') == 'postgresql_database' and len(doc.page_content) > 2000:\n",
    "            splits = text_splitter.split_documents([doc])\n",
    "            # Update metadata for splits\n",
    "            for i, split in enumerate(splits):\n",
    "                split.metadata.update({\n",
    "                    'split_index': i,\n",
    "                    'original_length': len(doc.page_content),\n",
    "                    'is_split': True\n",
    "                })\n",
    "            final_documents.extend(splits)\n",
    "        else:\n",
    "            # Keep PDF chunks and smaller DB docs as-is\n",
    "            final_documents.append(doc)\n",
    "    \n",
    "    return final_documents\n",
    "\n",
    "# Apply smart splitting\n",
    "processed_documents = smart_split_documents(all_documents)\n",
    "\n",
    "print(f\"üìä Document Processing Summary:\")\n",
    "print(f\"   ‚Ä¢ Original documents: {len(all_documents)}\")\n",
    "print(f\"   ‚Ä¢ After smart splitting: {len(processed_documents)}\")\n",
    "\n",
    "# Create the vector store\n",
    "qdrant_vectorstore = Qdrant.from_documents(\n",
    "    processed_documents,\n",
    "    embedding_model,\n",
    "    location=\":memory:\",\n",
    "    collection_name=\"northwind_comprehensive_data\",\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Created Qdrant vector store with {len(processed_documents)} documents (PDF + Database)\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 5. Create Score-Filtered Retriever\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Created score-filtered retriever\n"
     ]
    }
   ],
   "source": [
    "# Create a simple score-filtered retriever\n",
    "from langchain.schema import BaseRetriever, Document\n",
    "from typing import List, Any\n",
    "from pydantic import Field\n",
    "\n",
    "class ScoreFilteredRetriever(BaseRetriever):\n",
    "    \"\"\"Simple retriever that filters results by similarity score.\"\"\"\n",
    "    \n",
    "    vectorstore: Any = Field()\n",
    "    score_threshold: float = Field(default=0.5)\n",
    "    k: int = Field(default=5)\n",
    "    \n",
    "    class Config:\n",
    "        arbitrary_types_allowed = True\n",
    "    \n",
    "    def _get_relevant_documents(self, query: str) -> List[Document]:\n",
    "        docs_with_scores = self.vectorstore.similarity_search_with_score(query, k=self.k)\n",
    "        \n",
    "        # Filter by score threshold\n",
    "        filtered_docs = [\n",
    "            doc for doc, score in docs_with_scores \n",
    "            if score >= self.score_threshold\n",
    "        ]\n",
    "        \n",
    "        return filtered_docs\n",
    "\n",
    "# Create the retriever\n",
    "retriever = ScoreFilteredRetriever(\n",
    "    vectorstore=qdrant_vectorstore,\n",
    "    score_threshold=0.3,\n",
    "    k=8\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Created score-filtered retriever\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 6. Create RAG Prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Created RAG prompt template\n"
     ]
    }
   ],
   "source": [
    "# Define the enhanced RAG prompt template\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "RAG_PROMPT = \"\"\"\n",
    "CONTEXT:\n",
    "{context}\n",
    "\n",
    "QUERY:\n",
    "{question}\n",
    "\n",
    "You are a helpful assistant with access to comprehensive Northwind Traders information from both:\n",
    "1. Database Overview PDF documentation (structural information)\n",
    "2. Live database analysis reports (current business data and performance metrics)\n",
    "\n",
    "Use the provided context to answer the question thoroughly. If you can't answer the question based on the context, say you don't know. When possible, distinguish between structural/design information and actual business performance data.\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "rag_prompt = ChatPromptTemplate.from_template(RAG_PROMPT)\n",
    "print(\"‚úÖ Created enhanced RAG prompt template\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 7. Create RAG Chain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Initialized OpenAI chat model\n"
     ]
    }
   ],
   "source": [
    "# Initialize the LLM\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "print(\"‚úÖ Initialized OpenAI chat model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Created RAG chain\n"
     ]
    }
   ],
   "source": [
    "# Create the RAG chain\n",
    "from operator import itemgetter\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": itemgetter(\"question\") | retriever, \"question\": itemgetter(\"question\")}\n",
    "    | rag_prompt \n",
    "    | llm \n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Created RAG chain\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 8. Test the RAG System\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ Testing RAG System:\n",
      "\n",
      "================================================================================\n",
      "\n",
      "üîç Question 1: What are the main entities in the Northwind database?\n",
      "------------------------------------------------------------\n",
      "The main entities in the Northwind database are:\n",
      "\n",
      "1. **Customers** - Represents companies or individuals who purchase products.\n",
      "2. **Products** - Manages the product catalog and inventory of specialty food items.\n",
      "3. **Employees** - Holds information about staff members and their roles within the organization.\n",
      "4. **Orders** - Represents customer orders, linking them to customers and employees.\n",
      "5. **Order Details** - Links specific products to orders, representing the items sold.\n",
      "6. **Suppliers** - Represents entities that provide products to Northwind.\n",
      "7. **Categories** - Categorizes products based on their type.\n",
      "8. **Territories** - Defines geographic regions for sales representatives.\n",
      "9. **Regions** - Groups territories into larger geographical regions.\n",
      "10. **Shippers** - Handles shipping logistics for orders.\n",
      "\n",
      "These entities model the core business operations of the Northwind Traders company.\n",
      "\n",
      "üìä Retrieved 8 documents\n",
      "\n",
      "================================================================================\n",
      "\n",
      "üîç Question 2: How does the order processing system work?\n",
      "------------------------------------------------------------\n",
      "The order processing system at Northwind is structured around a series of interconnected tables in their database. Here's how it works:\n",
      "\n",
      "1. **Order Placement**: When a customer places an order, the details are recorded in the Orders table. An entry is created that captures high-level information such as the customer ID (linking to the Customers table), employee ID (linking to the Employees table), order date, required date, and shipment details.\n",
      "\n",
      "2. **Line Items Recording**: Each product in the order is documented in the Order Details table as individual line items. This table records the specific products and quantities ordered, along with unit prices and any discounts. The primary key in this table is a composite of the OrderID and ProductID, uniquely identifying each line item.\n",
      "\n",
      "3. **Inventory Update**: Once the order is saved, the inventory is updated in the Products table. The system adjusts the UnitsInStock for each product based on the quantities ordered. If the stock of any product falls below its reorder level due to the order, it triggers the purchasing team to restock.\n",
      "\n",
      "4. **Order Fulfillment**: The staff assigns a shipper (for example, Speedy Express) and prepares the goods for shipping. They update the Orders record with the actual ship date and freight charges. Customers can request changes to shipping addresses, which can be updated in the Orders table without altering the primary customer address.\n",
      "\n",
      "5. **Invoicing**: Once payment is received and the order is shipped, an invoice can be generated, pulling relevant information from the Customers, Orders, and Order Details tables to compile the necessary details.\n",
      "\n",
      "6. **Tracking and Completion**: The design ensures that every order can be tracked through to fulfillment. By retaining links between the tables, the system allows for comprehensive tracking of what was ordered, by whom, how it was shipped, and what the costs were.\n",
      "\n",
      "In summary, Northwind's order processing system effectively utilizes interconnected database tables to handle the flow from order placement to fulfillment while ensuring accurate inventory management and record-keeping.\n",
      "\n",
      "üìä Retrieved 8 documents\n",
      "\n",
      "================================================================================\n",
      "\n",
      "üîç Question 3: What information is stored in the Customers table?\n",
      "------------------------------------------------------------\n",
      "The Customers table in the Northwind database stores key information about the clients who place orders. Each record represents one customer (often a company) and includes the following fields:\n",
      "\n",
      "- **CustomerID**: The primary key that uniquely identifies the customer (usually a short alphanumeric code).\n",
      "- **CompanyName**: The name of the customer company.\n",
      "- **ContactName**: The primary contact person's name.\n",
      "- **ContactTitle**: The title of the primary contact person.\n",
      "- **Address**: The customer's street address.\n",
      "- **City**: The city where the customer is located.\n",
      "- **Region**: The region or state of the customer's address.\n",
      "- **PostalCode**: The postal code of the customer's address.\n",
      "- **Country**: The country of the customer.\n",
      "- **Phone**: The contact phone number.\n",
      "- **Fax**: The contact fax number.\n",
      "\n",
      "The Customers table also serves as a central hub for customer management processes by providing a comprehensive view of each client and supporting analysis related to orders and customer demographics. It maintains a one-to-many relationship with the Orders table, meaning a customer can have multiple orders.\n",
      "\n",
      "üìä Retrieved 8 documents\n",
      "\n",
      "================================================================================\n",
      "\n",
      "üîç Question 4: Describe the relationship between Orders and Order Details tables.\n",
      "------------------------------------------------------------\n",
      "The Orders and Order Details tables have a one-to-many relationship. Each order recorded in the Orders table is identified by a unique OrderID, which serves as the primary key. This OrderID is referenced in the Order Details table, meaning that one order can have multiple line items corresponding to the products included in that order.\n",
      "\n",
      "In detail, the Orders table captures high-level information such as the customer who placed the order, the employee who handled it, and shipping details. Each row in the Order Details table corresponds to a specific product included in that order, identified by both the OrderID and the associated ProductID. Thus, for each order in the Orders table, there can be multiple rows in the Order Details table representing the different products ordered, allowing for a detailed view of the contents of each sale. This design effectively models the order fulfillment process, linking orders, products, and their quantities together.\n",
      "\n",
      "üìä Retrieved 8 documents\n",
      "\n",
      "================================================================================\n",
      "\n",
      "üîç Question 5: What are the key business processes supported by Northwind?\n",
      "------------------------------------------------------------\n",
      "The key business processes supported by Northwind include:\n",
      "\n",
      "1. Managing customer information.\n",
      "2. Processing and fulfilling orders.\n",
      "3. Tracking products and inventory levels.\n",
      "4. Coordinating with suppliers for procurement.\n",
      "5. Managing shipping logistics.\n",
      "6. Organizing employee roles and sales territories.\n",
      "\n",
      "üìä Retrieved 8 documents\n"
     ]
    }
   ],
   "source": [
    "# Test the enhanced RAG system with comprehensive questions\n",
    "test_questions = [\n",
    "    \"What are the main entities in the Northwind database?\",\n",
    "    \"Who are the top performing customers and employees?\", \n",
    "    \"What are the best selling products and their suppliers?\",\n",
    "    \"How does the order processing system work?\",\n",
    "    \"What are the shipping and logistics insights?\",\n",
    "    \"Describe customer demographics and geographic distribution.\",\n",
    "    \"What inventory management challenges does Northwind face?\"\n",
    "]\n",
    "\n",
    "print(\"üß™ Testing Enhanced RAG System (PDF + Database):\\n\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for i, question in enumerate(test_questions, 1):\n",
    "    print(f\"\\nüîç Question {i}: {question}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    # Get response\n",
    "    response = rag_chain.invoke({\"question\": question})\n",
    "    print(response)\n",
    "    \n",
    "    # Show retrieved documents info and sources\n",
    "    docs = retriever.invoke(question)\n",
    "    pdf_docs = sum(1 for doc in docs if doc.metadata.get('data_source') != 'postgresql_database')\n",
    "    db_docs = sum(1 for doc in docs if doc.metadata.get('data_source') == 'postgresql_database')\n",
    "    \n",
    "    print(f\"\\nüìä Retrieved {len(docs)} documents ({pdf_docs} PDF, {db_docs} Database)\")\n",
    "    \n",
    "    if i < len(test_questions):\n",
    "        print(\"\\n\" + \"=\" * 80)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 9. Interactive Q&A\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive question-answering function\n",
    "def ask_question(question: str):\n",
    "    \"\"\"Ask a question and get an answer from the RAG system.\"\"\"\n",
    "    print(f\"üîç Question: {question}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    # Get response\n",
    "    response = rag_chain.invoke({\"question\": question})\n",
    "    print(f\"ü§ñ Answer: {response}\")\n",
    "    \n",
    "    # Show retrieved documents\n",
    "    docs = retriever.invoke(question)\n",
    "    print(f\"\\nüìö Used {len(docs)} source documents for context\")\n",
    "    \n",
    "    return response\n",
    "\n",
    "# Example usage:\n",
    "# ask_question(\"Who are the employees mentioned in the Northwind database?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Question: Who are the employees mentioned in the Northwind database?\n",
      "------------------------------------------------------------\n",
      "ü§ñ Answer: The context does not provide specific names of employees in the Northwind database. It discusses employee roles and organizational structure but does not list any individual employees. Therefore, I don't know the names of the employees mentioned in the Northwind database.\n",
      "\n",
      "üìö Used 8 source documents for context\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"The context does not provide specific names of employees in the Northwind database. It discusses employee roles and organizational structure but does not list any individual employees. Therefore, I don't know the names of the employees mentioned in the Northwind database.\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask_question(\"Who are the employees mentioned in the Northwind database?\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Enhanced System Summary\n",
    "\n",
    "This comprehensive RAG system provides:\n",
    "\n",
    "### ‚úÖ **Core Features**\n",
    "- **Smart PDF Chunking**: Section-based chunking with tiktoken token counting\n",
    "- **Database Integration**: Live business analysis from PostgreSQL database\n",
    "- **Dual Knowledge Sources**: PDF documentation + real business data\n",
    "- **High-Quality Embeddings**: OpenAI text-embedding-3-small model\n",
    "- **Intelligent Storage**: Qdrant vector store with smart document splitting\n",
    "- **Filtered Retrieval**: Score-based document filtering for relevance\n",
    "- **Enhanced RAG Chain**: Multi-source prompt ‚Üí LLM ‚Üí response pipeline\n",
    "\n",
    "### üéØ **Key Benefits**\n",
    "- **Comprehensive Knowledge**: Combines structural docs + live business data\n",
    "- **Token-Optimized**: Precise token counting for embedding model compatibility\n",
    "- **Structure-Preserving**: Maintains PDF section hierarchy in chunks\n",
    "- **Current Business Insights**: Real customer, product, and performance data\n",
    "- **Smart Document Handling**: Automatic splitting of large database reports\n",
    "- **Fast & Reliable**: Simple architecture with proven components\n",
    "- **Easy to Use**: Straightforward interface for comprehensive Q&A\n",
    "\n",
    "### üìä **Data Sources**\n",
    "1. **PDF Documentation**: Database structure, relationships, and design\n",
    "2. **Database Reports**: Live customer analysis, product performance, employee metrics, supplier data, shipping insights, and financial performance\n",
    "\n",
    "### üöÄ **Usage**\n",
    "```python\n",
    "# Ask any question about Northwind structure OR business performance\n",
    "response = rag_chain.invoke({\"question\": \"Your question here\"})\n",
    "print(response)\n",
    "\n",
    "# Examples:\n",
    "# - \"What are the database entities?\" (PDF source)\n",
    "# - \"Who are the top customers?\" (Database source)  \n",
    "# - \"How does order processing work?\" (Both sources)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
